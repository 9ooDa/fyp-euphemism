{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import KeyedVectors, Word2Vec, FastText\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    answer = defaultdict(list)\n",
    "\n",
    "    with open('data/euphemism_answer_drug.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        pattern = '[;\\\\n]+'\n",
    "\n",
    "        for l in lines:\n",
    "            l = l.lower()\n",
    "            val = l.split(':')[0]\n",
    "            keys = l.split(':')[1]\n",
    "            keys = re.split(pattern, keys)\n",
    "            \n",
    "            for k in keys:\n",
    "                if len(k) == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    answer[k.strip()].append(val)\n",
    "\n",
    "    drug_euphemism = sorted(list(set([x[0] for x in answer.items()])))\n",
    "    drug_formal = sorted(list(set([y for x in answer.items() for y in x[1]])))\n",
    "\n",
    "\n",
    "    target_dict = {}\n",
    "    count = 0\n",
    "\n",
    "    # target_emb = []\n",
    "\n",
    "    with open('data/target_keywords_drug.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip().split('\\t')\n",
    "            for i in l:\n",
    "                target_dict[i.strip()] = count\n",
    "            count += 1\n",
    "        \n",
    "        # for l in lines:\n",
    "        #     target_emb.append(l.strip().split('\\t'))\n",
    "\n",
    "\n",
    "    euph = []\n",
    "\n",
    "    with open('data/AutoPhrase_multi-words.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            l = l.strip().split('\\t')\n",
    "            for i in range(len(l)):\n",
    "                if i%2 != 0:\n",
    "                    euph.append(l[i])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return answer, drug_formal, target_dict, euph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_w2v_embed(target, data, emb):\n",
    "    if target is False:\n",
    "        sentences = LineSentence(data)\n",
    "        \n",
    "        model = Word2Vec(sentences, window=6, vector_size=100, min_count=5, alpha=0.0001, workers=30)\n",
    "        model.wv.save_word2vec_format(emb, binary=False)\n",
    "    else:\n",
    "        model = Word2Vec(data, window=6, vector_size=100, min_count=1, alpha=0.0001, workers=30)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_test(euphemism_answer, top_words, input_keywords):\n",
    "    final_test = {}\n",
    "    for x in top_words:\n",
    "        if x in euphemism_answer:\n",
    "            if any(e in euphemism_answer[x] for e in input_keywords):\n",
    "                final_test[x] = euphemism_answer[x]\n",
    "            else:\n",
    "                final_test[x] = ['None']\n",
    "        else:\n",
    "            final_test[x] = ['None']\n",
    "    return final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final(fin_out, fin_test, target_n):\n",
    "    ranking_list = []\n",
    "    target_n_list = []\n",
    "\n",
    "    for i in range(max(target_n.values())+1): # iterate throught all the drug names \n",
    "        target_n_list.append([x for x in target_n if target_n[x] == i]) # put in the same list if the count are equal\n",
    "\n",
    "    for i, word in enumerate(fin_test):\n",
    "        pos = 0\n",
    "        for j in fin_out[i]:\n",
    "            pos += 1\n",
    "            if any(e in target_n_list[j] for e in fin_test[word]):\n",
    "                break\n",
    "        ranking_list.append(pos)\n",
    "\n",
    "    print('Average ranking is {:.2f} for {:d} euphemisms.'.format(sum(ranking_list)/len(ranking_list), len(ranking_list)))\n",
    "\n",
    "    topk_acc = [sum(x <= k + 1 for x in ranking_list) / len(fin_test) for k in range(len(target_n_list))]\n",
    "    print('[Top-k Accuracy]: ', end='')\n",
    "    \n",
    "    for k in range(len(target_n_list)):\n",
    "        print('|  {:2d}  '.format(k + 1), end='')\n",
    "    print()\n",
    "    print(' ' * 18, end='')\n",
    "    \n",
    "    for k in range(len(target_n_list)):\n",
    "        print('| {:.2f} '.format(topk_acc[k]), end='')\n",
    "    print()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bullshit', 'zealand', 'officials', 'kept', 'flairing', 'style', 'chance', 'obscure', 'stars', 'friend', '21st', 'mountain', 'tree', 'children', 'forcing', 'thrills', 'lube', 'bill', 'occured', 'captcha', 'so', 'empath', 'gwern', 'oil', 'state', 'protection', 'relaxed', 'today', 'latest', 'leaning', 'host', 'hall', 'using', 'mr', 'guys', 'breathing', 'verification', 'lifetime', 'midst', 'behold', 'margins', 'website', 'highest', 'scope', 'successfully', 'quiet', 'logging', 'sudden', 'heshe', 'privileges', 'reminder', 'flavor', 'mix', 'lmk', 'consisted', 'ordered', 'gas', 'packaging', 'figure', 'diamond', 'quicker', 'informed', 'upper', 'stepped', 'starbucks', 'holyghost', 'esp', 'companies', 'neighborhood', 'purefire', 'rbitcoin', 'overwhelmed', 'steady', 'neat', 'comm', 'tor', 'breach', 'settings', 'export', 'confirm', 'reduced', 'hypothetically', 'r039', 'acropolis', 'might', 'opted', 'died', 'negative', 'beautifully', 'withdrawn', 'afford', 'hypothetical', 'education', 'mixture', 'nerves', 'attacker', 'remaining', 'laptop', '33', 'backlog', 'layers', 'conclusions', 'petty', 'estimates', 'ads', 'addressed', 'copying', 'incredible', 'angel', 'documentary', 'traditional', 'und', 'that', 'recover', 'detect', 'many', 'worked', 'jesus', 'ddos', '750mg', 'wallet', 'dissolved', 'ether', 'yeah', 'drinks', 'threaten', 'euphoric', 'card', 'raid', '5pm', 'calculated', 'db', 'hairs', 'stole', 'signals', 'ur', 'stamped', 'jars', 'ecstasydata', 'depth', 'kpacks', 'rs6', 'suspicions', 'timely', '6apb', 'dick', 'shockjohnson', 'wouldnt', 'restart', 'krispykreme', 'fault', 'greensails', 'rent', 'teslas', 'accounts', 'gain', 'complained', 'different', 'somehow', 'speculation', 'xanaxbaron', 'legitimate', '$1000', 'registration', 'north', 'ecig', 'sugar', 'drpill', 'uripmeth9000', 'picture', 'deadline', 'bummed', 'my', 'vacuum', 'healthy', 'seuss', '1000', 'forever', 'felt', 'here<url>', 'trigger', 'good', 'initially', 'link', 'teams', '|', 'radar', 'decisions', 'light', 'moreso', 'systems', 'sums', 'sourcing', 'various', '65mg', 'close', 'checkbox', 'barbarossa', 'cn', 'loves', 'btw', 'partysquad', 'offered', 'attempted', 'carts', 'lostheaven', 'winners', 'ssn', 'rest', 'markets', 'xl', 'strategy', 'ordering', 'mdmalsd', 'debian', 'gun', 'world', 'siezed', 'developing', 'comparison', 'carpet', 'agree', 'ii', 'tab', 'destroyed', 'speaker', 'avid', 'threatening', 'receipt', 'incoming', 'expect', 'headband', '160', 'isis', 'late', 'moderators', 'senders', 'sorts', 'supports', 'ibogaine', '50+', 'weighs', 'methadone', 'sign', 'test', 'guess', 'laptops', 'tone', 'flawless', 'stronger', 'grabbed', '19th', 'da', 'diferent', 'snort', 'anymore', 'written', 'forget', '$', 'impression', 'ignored', 'mixing', 'seize', 'busiest', 'editing', 'residence', 'variety', 'trying', 'clumps', 'distillate', 'longest', 'martymchigh', 'bond', 'lovely', 'burned', 'crack', 'are', 'andor', 'bang', 'addiction', 'twowolves', '100g', 'surprised', 'scene', 'understandable', 'rondoe', 'offdabrick', 'ingredients', 'introducing', 'tossed', 'business', 'hard', '3040', 'onto', 'soooo', 'obviously', 'meth', 'toasted', 'start', 'output', 'namemarketplace|', 'credentials', 'complete', 'contain', '24h', 'incl', 'duty', 'this', 'holds', 'brands', 'main', 'dangerous', 'racemic', 'regulated', 'needlepoint', 'mega', 'perform', 'storage', 'providing', 'arrested', 'tangerine', 'sold', 'crimes', 'comedown', 'liebermann', 'hear', 'unmarked', 'sociable', 'laid', 'fund', 'frosty', 'bbmc', 'bc', 'criticism', 'selective', 'building', 'saline', 'gw', 'ringo', 'practically', 'pills', 'rated', 'application', '1k', 'freezer', 'slightest', 'stolen', 'google', 'bro', 'ak47', 'fingerprint', 'pinky', 'lacking', 'diesel', 'mids', 'memes', 'loveisthekey', 'serve', 'universe', 'benzochems', 'freedom', 'accident', 'norway', 'undoubtedly', 'wont', 'off', 'gotmilk', 'refunds', 'partial', 'conditions', 'bodyload', 'kicks', 'tasted', 'sol', 'kids', 'encrypted', 'pants', 'com', 'missing', '24hrs', 'gorilla', 'danknation', 'dutchfarmernl', 'love', 'whatever', 'satisfied', '$19', 'ehrlich', '$800', 'seven', 'apart', 'scoop', 'except', 'decrypt', '025', 'ammonium', 'passwords', '2017', 'decent', 'burnt', 'mulanketma', 'avengers', 'investigate', 'creator', 'pharmaceutical', 'toptierdrugs', 'brazzers', 'reduce', 'disappeared', 'majorkey', 'animal', 'sink', 'ago', 'mistresstab', 'may', 'goddamn', '>this', '91', 'motherfucker', 'lord', 'relaxing', 'casual', 'doctordrugs', 'privacy', 'clock', 'household', 'protected', 'committed', 'overdoses', 'seriously', 'ui', 'pizza', 'k', 'alone', 'we', 'exposure', 'brazil', 'cure', 'vyvanse', 'pineapple', '25', 'gold', 'afterwards', 'often', 'investigative', 'headstash2you', '2gs', 'change', 'ravehunter', 'infront', 'crumble', 'caliconnection', 'letter', 'razor', 'thousand', 'python', 'weekends', 'cbsa', 'noise', 'smack', 'steam', 'london', 'username', 'peer', 'explaining', 'pharmacies', 'honey', 'harsh', 'fourth', '50', 'prezc', 'analogues', 'cannabinoids', 'lordxanax', 'prime', 'international', 'ip', 'alas', 'mnemonic', 'immediately', 'arose', 'soo', 'consists', 'talking', 'organizations', 'md', 'couchlock', 'jacked', 'gay', 'logs', 'sweaty', 'sorry', 'danger', 'tbh', '2cs', 'darknets', 'familiarize', 'meeting', 'shit', 'bbc', 'bleach', 'should', 'pet', 'sizzle', 'hurricane', 'denmark', 'tahoe', 'prescribed', 'joy', 'distributed', 'rub', 'libertarian', 'relatively', 'tldr', 'exchanges', 'little', 'medellin', 'measure', 'accordingly', 'hide', 'surroundings', 'dosage', 'vehicle', 'selectively', 'sincerely', 'discourse', 'ruined', 'difficulty', 'jiffy', 'bomb', '$30000', 'zero', 'msm', '|||', 'via', 'traphouse', 'ears', 'results', 'tin', 'line', 'cannaxpress000', 'three', '2day', 'requested', 'ladies', 'kks', 'subjects', 'tear', 'transferring', 'either', 'compete', 'flaws', 'goodbye', 'pray', 'welcomed', 'motherfucking', 'mdmazingusa', 'ofcourse', 'feds', 'gelman', 'promoting', 'beta', 'inexpensive', '2000', '3meopcp', 'multisig', 'protocol', 'small', 'vacation', 'assume', 'notberniesanders', 'subpar', 'knock', 'leverage', 'safer', 'upside', 'bird', 'favor', 'waste', 'psaarticle', 'guaranteed', 'convincing', 'regularly', 'entirely', 'flash', 'raided', 'drivers', 'messy', 'didnt', 'rising', 'reason', 'punch', 'beauty', 'em', 'excitement', 'rarely', 'whoever', 'cartelnorteafrica', '5th', 'personally', 'reset', 'false', 'requesting', 'got', '$500', '85', 'bearschoice', 'faster', 'perfect', 'popularity', 'largely', 'links', 'hulk', 'bitching', 'prefer', '125', 'consumer', 'rocks', 'fe', 'import', '$1', 'caused', 'on', 'visit', 'containing', 'registered', 'grade', 'party', 'shadowrx', 'express', 'eight', 'dig', 'tolerance', 'clever', 'map', 'attribute', 'condition', 'soap', 'majestic', 'damp', 'agency', 'usausa', 'ekekos', 'gained', 'deliver', 'effectively', 'fishwithscales', 'patiently', 'carton', 'featured', 'already', '100100', '90s', 'satisfactory', 'cia', 'cyber', 'college', 'disputes', 'neatly', 'ships', 'smell', 'whonix', 'blank', 'comprehensive', 'sidebar', 'substitute', 'know', 'parkinsons', 'marking', 'penguinmixer', 'liston', 'shitting', 'feed', 'bother', 'convicted', 'spiritual', 'created', 'man', 'competent', 'than', 'again', 'dosed', 'bread', 'resort', 'breaks', 'mahakala', 'gov', 'cos', 'company', 'bad', 'guidance', 'kenya', '1120', 'greater', 'collection', '$270', 'knew', 'seperate', 'psychedelic', 'cop', 'reximus', 'anyhow', 'aeirla', 'microdot', 'total', '$160', 'bottle', 'tube', 'update', '1010', 'repeated', 'creative', 'qualityrx', 'timeafter', 'noticing', 'weekly', 'not', 'nearly', 'promote', 'organized', 'fixed', 'america', 'smooth', 'vague', 'til', 'stopped', 'thestealthsuite', 'gunna', 'particular', 'fuf', 'separated', '3', 'restrictions', 'enabling', 'printer', 'spotted', 'blockchain', '8th', 'strive', 'clenching', 'skywalker', '7', 'ridiculously', 'charges', 'improved', 'continuing', 'device', 'tastes', 'jsl', 'klx123', '|yes', 'jor', 'analogue', 'surprise', 'epsom', 'overmind', 'cigars', 'southern', 'photo', 'hike', 'uncutking', 'dpr', 'retrieve', 'bitcloak', 'groups', 'miss', '$1500', 'desert', 'sorting', 'certifications', 'include', 'popped', 'controlled', 'mac', 'numbing', 'funniest', 'volumetric', 'innocent', 'no', 'they', 'inventory', 'star', 'trading', 'experience', 'fear', '70', 'm30s', 'tough', 'lately', 'emoji', 'isomer', 'lil', 'hack', 'internal', 'opiate', 'blown', 'varying', 'bsm', 'tape', 'thorough', 'hclmethanol', 'indeed', '94', 'supplies', 'syringe', 'signup', 'suppose', 'boy', 'reaction', 'transition', 'similar', 'emotional', 'ounce', 'it', 'occasions', '6th', 'allows', 'lifted', 'vendormarketinquiry', 'goodness', '5050', 'reaches', 'reagents', 'sometimes', 'vacuumsealed', 'puresure', 'july', 'fail', 'teva', 'exchanged', 'cured', 'worrying', 'favourite', 'fullstack', '1835cartel', 'bike', 'declined', 'analysis', 'interpol', '3mg', 'closed', 'quickest', 'securely', 'profit', 'mails', 'clone', 'aesthetics', 'tumble', 'researched', 'two', 'smells', 'color', 'turned', 'promptly', 'budsanddrugs', 'dense', 'tomorrowlands', 'everyday', 'mentions', 'bitterness', 'distinguish', 'investigating', 'pressure', 'pic', 'marquis', 'fentmaster', 'finalization', '50$', 'infused', 'track', 'peace', 'politely', 'can', 'looks', 'testing', 'cares', 'trust', 'occasional', 'happychemist', 'exhale', 'sensitive', 'fun', '17th', 'ez', 'needs', 'consideration', 'cream', 'from', 'his', 'credit', 'listonishereusa', 'u4', 'darker', 'protonmail', 'slow', 'shipments', 'mrbiz', 'marks', 'royally', '800', '240', 'u', 'thread', 'filler', 'smoothly', 'glass', 'errors', 'bright', 'mildly', '500x', 'confusion', 'fluff', 'vendeep', 'increase', 'crumbled', 'afghan', 'space', 'needing', 'switch', 'alike', 'adulteration', '$1200', 'prolly', 'marleysmainman', '|dream', 'absolute', 'court', 'definitly', 'print', 'th', '30th', 'somebody', 'fewer', 'sleepy', 'services', 'monero', 'moroccan', 'filter', 'rdrugs', 'outta', 'instagram', 'files', 'atari', 'pond', 'spreading', 'labeling', 'defiantly', 'topnotch', 'air', 'buyers', 'producers', 'opiateconnect', 'prescription', 'wise', 'price', 'whose', 'nicest', 'seed', 'limit', 'pass', 'highs', 'medicinal', 'someones', 'william', 'phish', 'compact', 'difference', 'land', 'lead', 'double', 'flagged', 'haven', 'bull']\n"
     ]
    }
   ],
   "source": [
    "def w2v_detection():\n",
    "    answer, drug_formal, target_dict, euph = read_files()\n",
    "\n",
    "    c_file = 'data/input.txt'\n",
    "    e_file = 'enwiki-20221020-pages-articles-multistream-index.txt'\n",
    "     \n",
    "    w2v_model = train_w2v_embed(False, c_file, e_file)\n",
    "    \n",
    "    emb_dict = KeyedVectors.load_word2vec_format(emb_fn, binary=False, limit=20000)\n",
    "\n",
    "\n",
    "    '''Detection'''\n",
    "    target_vec = []\n",
    "    real_name = list(target_dict.keys())\n",
    "\n",
    "    for i, seed in enumerate(real_name):\n",
    "        if seed in emb_dict:\n",
    "            target_vec.append(emb_dict[seed])\n",
    "\n",
    "    target_vec = np.array(target_vec)\n",
    "    avg_target_vec = np.sum(target_vec, axis=0) / len(target_vec)\n",
    "\n",
    "    top_k = [x[0] for x in w2v_model.wv.similar_by_vector(avg_target_vec, topn=1000) if x[0] not in real_name]\n",
    "    print(top_k)\n",
    "\n",
    "    with open('/data/euphemism_word2vec_embedding.txt', 'w') as fout:\n",
    "        for i in top_k:\n",
    "            fout.write(i+'\\n')\n",
    "\n",
    "\n",
    "    '''Identification'''\n",
    "    euph_candidates = []\n",
    "    with open('data/AutoPhrase_multi-words.txt', 'r') as fin:\n",
    "        for line in fin:\n",
    "            euph_candidates.append(line.strip())\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "w2v_detection() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인풋파일로 임베딩 찾아서 타겟 임베딩이랑 비교하고 (window=2~5로 하면 phrase로 됨)\n",
    "# autophrase랑 비교해서 순위매기기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf42840c5253c66635351366f71543fb19083080d676bbd340381a7827cbdf14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
